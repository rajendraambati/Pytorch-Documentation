{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Examples"
      ],
      "metadata": {
        "id": "fzlxx6-m89JA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFeI1IQfnt_C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.autograd as auto\n",
        "import torch.optim as optim\n",
        "import torch.functional as F\n",
        "import torch.utils.data.dataset\n",
        "import torch.utils.data.dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([[0,1],[1,1],[1,0],[0,0]],dtype=torch.float32)\n",
        "y=torch.tensor([[1],[1],[1],[0]],dtype=torch.float32)"
      ],
      "metadata": {
        "id": "48k1L7lRoJex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.func=nn.Sequential(\n",
        "            nn.Linear(2,2),\n",
        "            nn.ReLU(),\n",
        "            #F.relu(),\n",
        "            nn.Linear(2,1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self,x):\n",
        "      predict=self.func(x)\n",
        "      return predict"
      ],
      "metadata": {
        "id": "cwUuIb4ZoYR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the neural network architecture\n",
        "class XORModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XORModel, self).__init__()\n",
        "        self.hidden = nn.Linear(2, 4)  # Input layer to first hidden layer\n",
        "        self.relu = nn.ReLU()            # Activation function for hidden layer\n",
        "        self.output = nn.Linear(4, 1)    # First hidden layer to output layer\n",
        "        self.sigmoid = nn.Sigmoid()      # Activation function for output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.output(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = XORModel()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)  # Stochastic Gradient Descent optimizer"
      ],
      "metadata": {
        "id": "Q8r9o9LgsBZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.MSELoss()\n",
        "model=Sigmoid()\n",
        "optimizer=optim.SGD(model.parameters(),lr=0.1)"
      ],
      "metadata": {
        "id": "dzm0G1Kipcqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "koHUSsmxqtfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(x,y,model,optimizer,criterion):\n",
        "  model.train()\n",
        "  for epoch in range(1000):\n",
        "    predict=model(x)\n",
        "    loss=criterion(predict,y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch%100==0:\n",
        "      print('epoch:',epoch,'loss:',loss.item())\n"
      ],
      "metadata": {
        "id": "cExah0ftpf2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(x,y,model,optimizer,criterion)"
      ],
      "metadata": {
        "id": "KY8Uw8uep0Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "t=model.forward(torch.tensor([1,1],dtype=torch.float32)).round()\n",
        "print(t.item())"
      ],
      "metadata": {
        "id": "KR5EDHEPpuFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([[0,1],[1,1],[1,0],[0,0]],dtype=torch.float32)\n",
        "model.eval()\n",
        "t=model.forward(torch.tensor(x,dtype=torch.float32)).round()\n",
        "print(t.data)"
      ],
      "metadata": {
        "id": "aa1clRWYqKGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "hokPqlAhrqES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_score(y.data,t.data))"
      ],
      "metadata": {
        "id": "OaoYfQSrsj7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.data"
      ],
      "metadata": {
        "id": "Pu9tm8Fcso7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.data"
      ],
      "metadata": {
        "id": "27Hz9hIzsrDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:  # Check if the parameter is trainable\n",
        "        print(f\"{name}: {param.data}\")"
      ],
      "metadata": {
        "id": "LcyBBNw0s3yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.rand(4,2,dtype=torch.float32))"
      ],
      "metadata": {
        "id": "XYPyGNNgvS75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(x,y):\n",
        "  for _ in range(1000):\n",
        "    #optimizer.ze\n",
        "    predict=model(x)\n",
        "    loss=(predict-y).pow(2).sum()\n",
        "    with torch.no_grad:\n",
        "      w.\n"
      ],
      "metadata": {
        "id": "IiMEbf6FuK5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: initialize a optimizer variables for each of these optimizer algorithms 1.Batch gradient descent 2.Stochastic gradient descent 3.mini batch gradient descent 4.momentum method 5.adagrad 6.rmsprop 7.adam , and for each optimizer how my data is look like\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ... (your existing code)\n",
        "\n",
        "# Optimizer initialization and data descriptions\n",
        "optimizers = {\n",
        "    \"Batch Gradient Descent\": optim.SGD(model.parameters(), lr=0.1),\n",
        "    \"Stochastic Gradient Descent\": optim.SGD(model.parameters(), lr=0.1),\n",
        "    \"Mini-Batch Gradient Descent\": optim.SGD(model.parameters(), lr=0.1),\n",
        "    \"Momentum\": optim.SGD(model.parameters(), lr=0.1, momentum=0.9),\n",
        "    \"Adagrad\": optim.Adagrad(model.parameters(), lr=0.1),\n",
        "    \"RMSprop\": optim.RMSprop(model.parameters(), lr=0.1),\n",
        "    \"Adam\": optim.Adam(model.parameters(), lr=0.001)  # Typically a lower learning rate for Adam\n",
        "}\n",
        "\n",
        "\n",
        "for name, optimizer in optimizers.items():\n",
        "    print(f\"\\nOptimizer: {name}\")\n",
        "    print(f\"Data Description:  {x.shape} input features, and {y.shape} target values.\")\n",
        "    print(\"Data Example (x): \",x)\n",
        "    print(\"Data Example (y): \",y)\n",
        "\n",
        "# Example usage of an optimizer\n",
        "# (You would typically use a loop here to iterate and update weights)\n",
        "# optimizer = optimizers[\"Adam\"]  # Choose your optimizer\n",
        "\n",
        "#Example training with an optimizer.\n",
        "def train_with_optimizer(x,y,model,optimizer,criterion):\n",
        "  model.train()\n",
        "  for epoch in range(100):\n",
        "    predict=model(x)\n",
        "    loss=criterion(predict,y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch%10==0:\n",
        "      print('epoch:',epoch,'loss:',loss.item())\n",
        "\n",
        "#train_with_optimizer(x,y,model, optimizers[\"Adam\"],criterion)\n",
        "# ... (rest of your code)"
      ],
      "metadata": {
        "id": "_ftE9xJzxMWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Generate synthetic data\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(100, 1) * 10  # 100 samples from 0 to 10\n",
        "y = 2 * x + 1 + np.random.randn(100, 1) * 2  # Linear relation with noise\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "X_train = torch.tensor(x, dtype=torch.float32)\n",
        "Y_train = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "# Step 2: Define the linear regression model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # One input feature and one output\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Instantiate the model\n",
        "model = LinearRegressionModel()\n",
        "\n",
        "# Step 3: Set up the loss function and optimizer\n",
        "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent\n",
        "\n",
        "# Step 4: Train the model using SGD\n",
        "epochs = 1000\n",
        "losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Shuffle data at the beginning of each epoch for stochasticity\n",
        "    indices = np.random.permutation(len(X_train))\n",
        "    X_train_shuffled = X_train[indices]\n",
        "    Y_train_shuffled = Y_train[indices]\n",
        "\n",
        "    for i in range(len(X_train)):\n",
        "        # Forward pass: Compute predicted y by passing X_train through the model\n",
        "        Y_pred = model(X_train_shuffled[i].view(1, -1))\n",
        "\n",
        "        # Compute and print loss\n",
        "        loss = criterion(Y_pred, Y_train_shuffled[i].view(1, -1))\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # Zero gradients before backward pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backward pass: Compute gradients of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters using gradients\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "# Plotting the loss over epochs\n",
        "plt.plot(losses)\n",
        "plt.title('Loss over epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "# Visualizing the results\n",
        "with torch.no_grad():\n",
        "    predicted = model(X_train).numpy()\n",
        "\n",
        "plt.scatter(x, y, color='blue', label='Original data')\n",
        "plt.plot(x, predicted, color='red', label='Fitted line')\n",
        "plt.title('Linear Regression Result')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w5mJZQmHyZRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Generate synthetic data\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(100, 1) * 10  # 100 samples from 0 to 10\n",
        "y = 2 * x + 1 + np.random.randn(100, 1) * 2  # Linear relation with noise\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "X_train = torch.tensor(x, dtype=torch.float32)\n",
        "Y_train = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "# Step 2: Define the linear regression model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # One input feature and one output\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Instantiate the model\n",
        "model = LinearRegressionModel()\n",
        "\n",
        "# Step 3: Set up the loss function and optimizer\n",
        "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent\n",
        "\n",
        "# Step 4: Train the model using SGD and track parameter updates\n",
        "epochs = 1000\n",
        "losses = []\n",
        "params_history = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range(len(X_train)):\n",
        "        # Forward pass: Compute predicted y by passing X_train through the model\n",
        "        Y_pred = model(X_train[i].view(1, -1))\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(Y_pred, Y_train[i].view(1, -1))\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # Zero gradients before backward pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backward pass: Compute gradients of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters using gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store parameters for visualization\n",
        "        params_history.append(model.linear.weight.item())\n",
        "        params_history.append(model.linear.bias.item())\n",
        "\n",
        "# Step 5: Plotting results\n",
        "\n",
        "# Plotting loss over epochs\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(losses)\n",
        "plt.title('Loss over epochs')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Plotting parameter updates in parameter space (weight vs bias)\n",
        "weights = params_history[::2]   # Extract weights from history\n",
        "biases = params_history[1::2]    # Extract biases from history\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(weights, biases, marker='o')\n",
        "plt.title('Parameter Space Trajectory')\n",
        "plt.xlabel('Weight')\n",
        "plt.ylabel('Bias')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TDdzxdHhzH5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Step 1: Define a simple quadratic loss function\n",
        "def loss_function(w, b):\n",
        "    return (w ** 2 + b ** 2)  # Simple bowl shape\n",
        "\n",
        "# Step 2: Generate a grid for weights and biases\n",
        "w_range = np.linspace(-3, 3, 100)\n",
        "b_range = np.linspace(-3, 3, 100)\n",
        "W, B = np.meshgrid(w_range, b_range)\n",
        "L = loss_function(W, B)\n",
        "\n",
        "# Step 3: Initialize parameters for SGD\n",
        "w = torch.tensor(2.0, requires_grad=True)  # Initial weight\n",
        "b = torch.tensor(2.0, requires_grad=True)  # Initial bias\n",
        "learning_rate = 0.1\n",
        "epochs = 50\n",
        "\n",
        "# Store paths for plotting\n",
        "path_w = []\n",
        "path_b = []\n",
        "\n",
        "# Step 4: Perform Stochastic Gradient Descent\n",
        "for epoch in range(epochs):\n",
        "    # Calculate loss\n",
        "    loss = loss_function(w, b)\n",
        "\n",
        "    # Zero gradients before backward pass\n",
        "    w.grad = None\n",
        "    b.grad = None\n",
        "\n",
        "    # Compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters using SGD\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "\n",
        "    # Store the path taken by w and b\n",
        "    path_w.append(w.item())\n",
        "    path_b.append(b.item())\n",
        "\n",
        "# Step 5: Plotting the loss surface and SGD path\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plotting the loss surface\n",
        "ax.plot_surface(W, B, L, cmap='viridis', alpha=0.7)\n",
        "\n",
        "# Plotting the path taken by SGD on top of the surface\n",
        "ax.plot(path_w, path_b, loss_function(torch.tensor(path_w), torch.tensor(path_b)), color='r', marker='o')\n",
        "\n",
        "ax.set_title('Loss Function Surface with SGD Path')\n",
        "ax.set_xlabel('Weight (w)')\n",
        "ax.set_ylabel('Bias (b)')\n",
        "ax.set_zlabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KaoCvmoAzddm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Step 1: Define a simple quadratic loss function\n",
        "def loss_function(w, b):\n",
        "    return (w ** 2 + b ** 2)  # Simple bowl shape\n",
        "\n",
        "# Step 2: Generate a grid for weights and biases\n",
        "w_range = np.linspace(-3, 3, 100)\n",
        "b_range = np.linspace(-3, 3, 100)\n",
        "W, B = np.meshgrid(w_range, b_range)\n",
        "L = loss_function(W, B)\n",
        "\n",
        "# Step 3: Initialize parameters for SGD\n",
        "w = torch.tensor(2.0, requires_grad=True)  # Initial weight\n",
        "b = torch.tensor(2.0, requires_grad=True)  # Initial bias\n",
        "learning_rate = 0.1\n",
        "epochs = 50\n",
        "\n",
        "# Store paths for plotting\n",
        "path_w = []\n",
        "path_b = []\n",
        "\n",
        "# Step 4: Perform Stochastic Gradient Descent\n",
        "for epoch in range(epochs):\n",
        "    # Simulate stochastic updates by selecting a random data point (in this case, just using w and b)\n",
        "    # In practice, you would use a single sample from your dataset.\n",
        "\n",
        "    # Calculate loss for the current parameters\n",
        "    loss = loss_function(w, b)\n",
        "\n",
        "    # Zero gradients before backward pass\n",
        "    w.grad = None\n",
        "    b.grad = None\n",
        "\n",
        "    # Compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters using SGD\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "\n",
        "    # Store the path taken by w and b\n",
        "    path_w.append(w.item())\n",
        "    path_b.append(b.item())\n",
        "\n",
        "# Step 5: Plotting the loss surface and SGD path\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plotting the loss surface\n",
        "ax.plot_surface(W, B, L, cmap='viridis', alpha=0.7)\n",
        "\n",
        "# Plotting the path taken by SGD on top of the surface\n",
        "ax.plot(path_w, path_b, loss_function(torch.tensor(path_w), torch.tensor(path_b)), color='r', marker='o')\n",
        "\n",
        "ax.set_title('Loss Function Surface with SGD Path')\n",
        "ax.set_xlabel('Weight (w)')\n",
        "ax.set_ylabel('Bias (b)')\n",
        "ax.set_zlabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9rP6a_R7z9qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Step 1: Define a simple quadratic loss function\n",
        "def loss_function(w, b):\n",
        "    return (w ** 2 + b ** 2)  # Simple bowl shape\n",
        "\n",
        "# Step 2: Generate a grid for weights and biases\n",
        "w_range = np.linspace(-3, 3, 100)\n",
        "b_range = np.linspace(-3, 3, 100)\n",
        "W, B = np.meshgrid(w_range, b_range)\n",
        "L = loss_function(W, B)\n",
        "\n",
        "# Step 3: Initialize parameters for Batch Gradient Descent\n",
        "w = torch.tensor(2.0, requires_grad=True)  # Initial weight\n",
        "b = torch.tensor(2.0, requires_grad=True)  # Initial bias\n",
        "learning_rate = 0.1\n",
        "epochs = 50\n",
        "\n",
        "# Store paths for plotting\n",
        "path_w = []\n",
        "path_b = []\n",
        "\n",
        "# Step 4: Perform Batch Gradient Descent\n",
        "for epoch in range(epochs):\n",
        "    # Calculate loss for the current parameters (using batch)\n",
        "    loss = loss_function(w, b)\n",
        "\n",
        "    # Zero gradients before backward pass\n",
        "    w.grad = None\n",
        "    b.grad = None\n",
        "\n",
        "    # Compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters using Batch Gradient Descent\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "\n",
        "    # Store the path taken by w and b\n",
        "    path_w.append(w.item())\n",
        "    path_b.append(b.item())\n",
        "\n",
        "# Step 5: Plotting the loss surface and Batch Gradient Descent path\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plotting the loss surface\n",
        "ax.plot_surface(W, B, L, cmap='viridis', alpha=0.7)\n",
        "\n",
        "# Plotting the path taken by Batch Gradient Descent on top of the surface\n",
        "ax.plot(path_w, path_b, loss_function(torch.tensor(path_w), torch.tensor(path_b)), color='r', marker='o')\n",
        "\n",
        "ax.set_title('Loss Function Surface with Batch Gradient Descent Path')\n",
        "ax.set_xlabel('Weight (w)')\n",
        "ax.set_ylabel('Bias (b)')\n",
        "ax.set_zlabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0EwIpr0Z0Uv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Generate synthetic data\n",
        "# For this example, we'll create a simple dataset\n",
        "np.random.seed(42)\n",
        "x_train = np.random.rand(100, 1) * 10  # 100 samples from 0 to 10\n",
        "y_train = 2 * x_train + 1 + np.random.randn(100, 1) * 0.5  # Linear relation with noise\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "# Create a DataLoader for batching\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Step 2: Define a simple linear regression model using nn.Module\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # One input feature and one output\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Step 3: Initialize the model, loss function, and optimizer\n",
        "model = LinearRegressionModel()\n",
        "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent\n",
        "\n",
        "# Step 4: Train the model\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    for xb, yb in train_loader:\n",
        "        # Forward pass: Compute predicted y by passing x to the model\n",
        "        y_pred = model(xb)\n",
        "\n",
        "        # Compute and print loss\n",
        "        loss = criterion(y_pred, yb)\n",
        "\n",
        "        # Zero gradients before backward pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backward pass: Compute gradients of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters using gradients\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "# Step 5: Evaluate the model (optional)\n",
        "with torch.no_grad():\n",
        "    x_test = torch.tensor([[5.0]], dtype=torch.float32)  # Test on a new sample\n",
        "    prediction = model(x_test)\n",
        "    print(f'Prediction for input {x_test.item()}: {prediction.item()}')"
      ],
      "metadata": {
        "id": "wx-K0ImZ0c2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([[0,1],[1,1],[1,0],[0,0]],dtype=torch.float32)\n",
        "y=torch.tensor([[1],[1],[1],[0]],dtype=torch.float32)"
      ],
      "metadata": {
        "id": "-7dTTpsp1Q8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "x=torch.tensor([[0,1],[1,1],[1,0],[0,0]],dtype=torch.float32)\n",
        "y=torch.tensor([[1],[1],[1],[0]],dtype=torch.float32)\n",
        "\n",
        "# Define the neural network architecture\n",
        "class XORModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XORModel, self).__init__()\n",
        "        self.hidden = nn.Linear(2, 4)  # Input layer to first hidden layer\n",
        "        self.relu = nn.ReLU()            # Activation function for hidden layer\n",
        "        self.output = nn.Linear(4, 1)    # First hidden layer to output layer\n",
        "        self.sigmoid = nn.Sigmoid()      # Activation function for output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.output(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = XORModel()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)  # Stochastic Gradient Descent optimizer"
      ],
      "metadata": {
        "id": "jrWmqsZM1Luw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Define the dataset\n",
        "x = torch.tensor([[0, 1], [1, 1], [1, 0], [0, 0]], dtype=torch.float32)\n",
        "y = torch.tensor([[1], [1], [1], [0]], dtype=torch.float32)\n",
        "\n",
        "# Define the neural network architecture\n",
        "class XORModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XORModel, self).__init__()\n",
        "        self.hidden = nn.Linear(2, 4)  # Input layer to first hidden layer\n",
        "        self.relu = nn.ReLU()            # Activation function for hidden layer\n",
        "        self.output = nn.Linear(4, 1)    # First hidden layer to output layer\n",
        "        self.sigmoid = nn.Sigmoid()      # Activation function for output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.output(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = XORModel()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)  # Stochastic Gradient Descent optimizer\n",
        "\n",
        "# Step 1: Generate a grid for weights and biases\n",
        "w1_range = np.linspace(-3, 3, 100)  # Range for first weight (input to hidden)\n",
        "w2_range = np.linspace(-3, 3, 100)  # Range for second weight (input to hidden)\n",
        "W1, W2 = np.meshgrid(w1_range, w2_range)\n",
        "\n",
        "# Step 2: Calculate loss for each combination of weights and biases\n",
        "loss_values = np.zeros(W1.shape)\n",
        "\n",
        "for i in range(W1.shape[0]):\n",
        "    for j in range(W1.shape[1]):\n",
        "        with torch.no_grad():\n",
        "            # Set model weights manually for visualization\n",
        "            model.hidden.weight.data[0][0] = W1[i][j]  # First weight (input to hidden)\n",
        "            model.hidden.weight.data[0][1] = W2[i][j]  # Second weight (input to hidden)\n",
        "            model.output.weight.data[0][0] = -2.0      # Fixed output weight for visualization\n",
        "            model.output.bias.data[0] = -2.0            # Fixed output bias for visualization\n",
        "\n",
        "            # Compute loss over all data points\n",
        "            y_pred = model(x)\n",
        "            loss_values[i][j] = criterion(y_pred, y).item()\n",
        "\n",
        "# Step 3: Perform Stochastic Gradient Descent and track the path taken by parameters\n",
        "path_w1 = []\n",
        "path_w2 = []\n",
        "\n",
        "# Training loop for a few epochs to visualize SGD path on the surface\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range(len(x)):\n",
        "        optimizer.zero_grad()   # Zero gradients before backward pass\n",
        "\n",
        "        y_pred = model(x[i].view(1, -1))  # Forward pass on a single sample\n",
        "\n",
        "        loss = criterion(y_pred, y[i].view(1, -1))  # Compute loss\n",
        "\n",
        "        loss.backward()         # Backward pass\n",
        "\n",
        "        optimizer.step()        # Update parameters\n",
        "\n",
        "        path_w1.append(model.hidden.weight.data[0][0].item())\n",
        "        path_w2.append(model.hidden.weight.data[0][1].item())\n",
        "\n",
        "# Step 4: Plotting the loss surface and SGD path\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plotting the loss surface\n",
        "ax.plot_surface(W1, W2, loss_values, cmap='viridis', alpha=0.7)\n",
        "\n",
        "# Plotting the path taken by SGD on top of the surface\n",
        "ax.plot(path_w1, path_w2,\n",
        "         np.array([loss_function(torch.tensor([w1]), torch.tensor([w2]))\n",
        "                   for w1, w2 in zip(path_w1, path_w2)]),\n",
        "         color='r', marker='o')\n",
        "\n",
        "ax.set_title('Loss Function Surface with SGD Path')\n",
        "ax.set_xlabel('Weight (w)')\n",
        "ax.set_ylabel('Bias (b)')\n",
        "ax.set_zlabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HEaFfGtc1VDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data.dataset as dataset"
      ],
      "metadata": {
        "id": "O5szzdmU1whX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import a dataset from dataset module after imported 'import torch.utils.data.dataset as dataset'\n",
        "\n",
        "# Assuming 'dataset' is already imported as 'import torch.utils.data.dataset as dataset'\n",
        "# and you have data in X_train and Y_train tensors\n",
        "\n",
        "# Create a TensorDataset from your tensors\n",
        "train_data = dataset.TensorDataset(X_train, Y_train)\n",
        "\n",
        "# Create a DataLoader to handle batching and shuffling\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "# Now you can iterate over the DataLoader\n",
        "for i, data in enumerate(train_loader):\n",
        "    inputs, labels = data\n",
        "    # ... your training logic here\n",
        "    print(f\"Batch {i+1}, Inputs shape: {inputs.shape}, Labels shape: {labels.shape}\")"
      ],
      "metadata": {
        "id": "p_iA3C-H2e4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "9E5Zms0z3HDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataSet(dataset.Dataset):\n",
        "    def __init__(self,x):\n",
        "        self.data=pd.read_csv(x)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self,idx):\n",
        "        features = self.data.iloc[idx, :-1].values  # All columns except the last\n",
        "        target = self.data.iloc[idx, -1]            # Last column\n",
        "        return torch.tensor(features, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "nDWDzDPu2xQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BLW7zddO3YDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dk=DataSet('/content/sample_data/california_housing_train.csv')"
      ],
      "metadata": {
        "id": "sGjcf29u3Ryn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):  # Print first 5 samples\n",
        "    features, target = dk[i]\n",
        "    print(f\"Sample {i}: Features = {features.numpy()}, Target = {target.item()}\")"
      ],
      "metadata": {
        "id": "jhKCsJrP3VII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader=DataLoader(dk,batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "K9q883424F1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader"
      ],
      "metadata": {
        "id": "szT623Wu5B34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (features, targets) in enumerate(dataloader):\n",
        "    print(f\"Batch {batch_idx + 1}:\")\n",
        "    print(\"Features:\\n\", features)\n",
        "    print(\"Targets:\\n\", targets)\n",
        "    print(\"-\" * 50)  # Separator for clarity\n",
        "\n",
        "    # Optionally break after printing a few batches for brevity\n",
        "    if batch_idx >= 4:  # Change this number based on how many batches you want to see\n",
        "        break"
      ],
      "metadata": {
        "id": "sjWXH23J5DdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Spam(dataset.Dataset):\n",
        "  def __init__(self,file):\n",
        "    with open(file,'r') as file:\n",
        "      lines=file.readlines()\n",
        "      lines=[line.strip() for line in lines]\n",
        "      self.data=pd.DataFrame(lines,columns=['label','text'])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self, index):\n",
        "    label=self.data.iloc[index]['label']\n",
        "    message=self.data.iloc[index]['text']\n",
        "    return label,message"
      ],
      "metadata": {
        "id": "EY8iXX355Q4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=Spam('spam.csv')"
      ],
      "metadata": {
        "id": "82aneiN363tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qnrHk_ct7Xe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch by Tsingua"
      ],
      "metadata": {
        "id": "dEBWErvf9E6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pytorch Installation"
      ],
      "metadata": {
        "id": "sclv0lIs9aKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "aw5W4uMT9Poo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working With Tensors"
      ],
      "metadata": {
        "id": "VrAcfOK99k0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "l9odoDs59hMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1=torch.tensor([1,2,3])"
      ],
      "metadata": {
        "id": "DXv0B8m49sxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1"
      ],
      "metadata": {
        "id": "YwxOBez29vgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array1=np.arange(12).reshape(3,4)"
      ],
      "metadata": {
        "id": "ykfpt0V79we7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array1"
      ],
      "metadata": {
        "id": "3c-9vXCr93dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "empty=torch.empty(3,4)"
      ],
      "metadata": {
        "id": "b9I2-lTi94WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones=torch.ones(3,4)"
      ],
      "metadata": {
        "id": "jCmCgF1_-BA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zeros=torch.zeros(3,4)"
      ],
      "metadata": {
        "id": "a7RRZELx-DcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand=torch.rand(3,4)"
      ],
      "metadata": {
        "id": "3dLmsS85-Ffr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones_like=torch.ones_like(empty)"
      ],
      "metadata": {
        "id": "eQf7QNJp-Ke7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list=['empty','ones','zeros','rand','ones_like']\n",
        "for j in range(5):\n",
        "  print(eval(list[j]))"
      ],
      "metadata": {
        "id": "YFketCzq-OJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand=torch.randint(3,4,(2,2))"
      ],
      "metadata": {
        "id": "GspTYsCB-2jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand"
      ],
      "metadata": {
        "id": "zhM0z8g5--ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor=torch.tensor(np.arange(10).reshape(2,5))"
      ],
      "metadata": {
        "id": "KKfOq7HO_Bjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor"
      ],
      "metadata": {
        "id": "4z_VR50u_MTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.data"
      ],
      "metadata": {
        "id": "mMiv_q6F_P5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ".item() fucntion is used to get the scaler value only from the tensor <br>\n",
        "if you want to get multiple scaler values or tensor data then you have to use .data"
      ],
      "metadata": {
        "id": "LyxqKPJf_c3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.numpy()"
      ],
      "metadata": {
        "id": "kokIpGc5_ZTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.size()"
      ],
      "metadata": {
        "id": "pDRdnON0_2L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.shape[1]"
      ],
      "metadata": {
        "id": "HZGxY1Mo_5QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.dim()"
      ],
      "metadata": {
        "id": "tBLNBqb8_8Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.view(5,2)"
      ],
      "metadata": {
        "id": "vK18joLeADi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.max()"
      ],
      "metadata": {
        "id": "qo3OmzosAG_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.median()"
      ],
      "metadata": {
        "id": "e2cLeqCiANXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t=tensor.to(dtype=torch.float32)"
      ],
      "metadata": {
        "id": "GuEmDltnAOO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_std(tensor):\n",
        "    # Check if the tensor is a floating point type\n",
        "    if not torch.is_floating_point(tensor):\n",
        "        print(f\"Converting tensor of type {tensor.dtype} to float.\")\n",
        "        tensor = tensor.float()  # Convert to float if it's not\n",
        "\n",
        "    std_value = tensor.std()  # Calculate standard deviation\n",
        "    return std_value"
      ],
      "metadata": {
        "id": "Q9dGA4gAAR_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_std(tensor)"
      ],
      "metadata": {
        "id": "sBQdbX63Aesc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.std()"
      ],
      "metadata": {
        "id": "km9Rz3m8AvU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.shape"
      ],
      "metadata": {
        "id": "nbhZSe56A_2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.t()"
      ],
      "metadata": {
        "id": "Kx4UAKp4A1o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor"
      ],
      "metadata": {
        "id": "xZs85gU2A6M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.permute(1,0)"
      ],
      "metadata": {
        "id": "HXxhZVxfBKgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[:1]"
      ],
      "metadata": {
        "id": "SlFzZXoIBgmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[:,1]"
      ],
      "metadata": {
        "id": "USJoB-E3BwH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dtypes"
      ],
      "metadata": {
        "id": "xJfgwezuCFDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.dtype"
      ],
      "metadata": {
        "id": "4mBs1FRrB9I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(torch.tensor)"
      ],
      "metadata": {
        "id": "B0YBgFCMCOXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.FloatTensor(1)"
      ],
      "metadata": {
        "id": "aQeig5dvCWGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.type(torch.float32)"
      ],
      "metadata": {
        "id": "d5zhkLU2DKGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.double()"
      ],
      "metadata": {
        "id": "kylOY-13DRmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor"
      ],
      "metadata": {
        "id": "E6tiTPUFC36x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "GfiN2384Dlp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.rand(5,5)"
      ],
      "metadata": {
        "id": "G9tjvPMfDXA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.type(torch.float32)"
      ],
      "metadata": {
        "id": "WCQ_C3QIDkoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype"
      ],
      "metadata": {
        "id": "WMapcEC0Drpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=torch.rand(5,5,dtype=torch.float32)"
      ],
      "metadata": {
        "id": "Cdw_cL_ODtLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "k-cDM4tED59u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x+y"
      ],
      "metadata": {
        "id": "PEuLNp9ED1h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.add(x,y)"
      ],
      "metadata": {
        "id": "1dyVl7UTD4bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.add_(y)"
      ],
      "metadata": {
        "id": "4c4wGGrOD97-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ff_XzYKHEBze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working With NVIDIA CUDA"
      ],
      "metadata": {
        "id": "y-wXOiPLEMR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  print('cuda is available')\n",
        "else:\n",
        "  device=torch.device('cuda')"
      ],
      "metadata": {
        "id": "Sv5ppZvKEPZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "RK_iQo9FEX_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "tq6KlbqgEegu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t"
      ],
      "metadata": {
        "id": "qezhHjpAElav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device=torch.device('cuda')\n",
        "  y=torch.torch.ones_liek(t,device=device)\n",
        "  x=torch.to(device)\n",
        "  z=x+y\n",
        "  print(z)\n",
        "  print(z.to('cpu',torch.double))\n",
        "else:\n",
        "  print('cuda is not available')"
      ],
      "metadata": {
        "id": "vccx5M-pExLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([1,2],device='cuda:0')"
      ],
      "metadata": {
        "id": "716KMweaFNYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Functions & Optimizers"
      ],
      "metadata": {
        "id": "yIHDMmVJGaJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "w=w-(alpha*(gradient of w))"
      ],
      "metadata": {
        "id": "7TTNRfEQHPcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x=torch.rand(2,2,requires_grad=True)"
      ],
      "metadata": {
        "id": "y4j9xZBTGl4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "mjAEraeUHrPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=torch.ones([1,2])"
      ],
      "metadata": {
        "id": "4MMKqvWBHw8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "sBbq4bmtH4ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=x*2+1"
      ],
      "metadata": {
        "id": "yx8RHDf7IASg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss=torch.sum(k-y)**2"
      ],
      "metadata": {
        "id": "47sxNYxoINDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.grad"
      ],
      "metadata": {
        "id": "aANM3K4OIQlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "id": "imAQ3KFeIcaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "x=torch.rand([50])\n",
        "y=3*x+0.8\n",
        "\n",
        "w=torch.rand(1,requires_grad=True)\n",
        "b=torch.rand(1,requires_grad=True)\n",
        "print(list([w,b]))\n",
        "def loss(y,y_pred):\n",
        "  return torch.mean((y_pred-y)**2)\n",
        "  for i in range(100):\n",
        "    y_pred=w*x+b\n",
        "    l=loss(y,y_pred)\n",
        "    l.backward\n",
        "    with torch.no_grad():\n",
        "      w-=0.01*w.grad\n",
        "      b-=0.01*b.grad\n",
        "      w.grad.zero_()"
      ],
      "metadata": {
        "id": "5a_m5YilIdfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "id": "EOVQ8yMQKdgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "id": "BBY41CNeKfbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "x=torch.rand([500,1])\n",
        "y=3*x+0.8"
      ],
      "metadata": {
        "id": "RjkQvaO-KgKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w=torch.rand(1,requires_grad=True)\n",
        "b=torch.rand(1,requires_grad=True)"
      ],
      "metadata": {
        "id": "0RrlqGOwK10C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "ph7UbI_BLB9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w.shape"
      ],
      "metadata": {
        "id": "Zz6LsJyXLDVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred= torch.matmul(x,w)+b"
      ],
      "metadata": {
        "id": "amVAFY5SK4Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss=(y-ypred).pow(2).mean()"
      ],
      "metadata": {
        "id": "nbOg4i5bK9bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(500):\n",
        "  if w.grad is not None:\n",
        "    w.grad.zero_()\n",
        "  if b.grad is not None:\n",
        "    b.grad.zero_()\n",
        "  loss.backward()\n",
        "  w-=0.01*w.grad\n",
        "  b-=0.01*b.grad"
      ],
      "metadata": {
        "id": "HuEORLPQLRMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=torch.optim.SGD([w,b],lr=0.01)\n",
        "optimizer.zero_grad()\n",
        "#loss=loss(y,ypred)\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "gANcZasBLeri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Artificial Neural Network"
      ],
      "metadata": {
        "id": "9DYtE4Y0MNg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "XevegWSwMJFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LR(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear=nn.Linear(1,1)\n",
        "  def forward(self,x):\n",
        "    pred=self.linear(x)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "Z9Ey5KFDMdLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=LR()"
      ],
      "metadata": {
        "id": "_gnuJ6sSMjaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict=model(x)"
      ],
      "metadata": {
        "id": "s9x32KPtMopz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict"
      ],
      "metadata": {
        "id": "A1MlWn4wM0bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "EA9lepbGM2cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(x,y,model,criterion,optimizer):\n",
        "  model.train()\n",
        "  for j in range(1000):\n",
        "    y_pred=model(x)\n",
        "    loss=criterion(y_pred,y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    if j%100==0:\n",
        "      print(f'epoch:{j} loss:{loss.item()}')\n"
      ],
      "metadata": {
        "id": "TJlHPQUxNDlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.randint(low=100,high=180,size=(100,1),dtype=torch.float32,device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
      ],
      "metadata": {
        "id": "02Gt6igKNTdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=torch.randint(low=10,high=90,size=(100,1),dtype=torch.float32,device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
      ],
      "metadata": {
        "id": "W_snf1wANrVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "Xqp_dIrNNQsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "ngS3IYFgN4L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(x,y,model,criterion,optimizer)"
      ],
      "metadata": {
        "id": "UlXnsqscN4vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "28dfQ4lWOBIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "s5onGYA9O2Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x)"
      ],
      "metadata": {
        "id": "-pwOINvMO3yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x,y)"
      ],
      "metadata": {
        "id": "02gUPMS7O6EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict=model(x)"
      ],
      "metadata": {
        "id": "WACQuhSqPJJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x.detach().numpy(), y.detach().numpy(), label='Data Points', color='blue')\n",
        "\n",
        "# Plot predictions\n",
        "plt.plot(x.detach().numpy(), predict.detach().numpy(), color='red', label='Predictions')\n",
        "\n",
        "# Add labels and legend\n",
        "plt.title(\"Scatter Plot with Predictions\")\n",
        "plt.xlabel(\"X-axis\")\n",
        "plt.ylabel(\"Y-axis\")\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z3tvjT8zPQFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Implementation Template** <br>\n",
        "1.import libraries <br>\n",
        "2.data load<br>\n",
        "3.data preparation<br>\n",
        "4.Neural network intialization<br>\n",
        "5.loss fuction<br>\n",
        "6.optimizer<br>\n",
        "7.model training<br>\n",
        "8.model testing"
      ],
      "metadata": {
        "id": "2nODVvnDtKqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "ryMNDSoEPYik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class lr(nn.Module):\n",
        "  def __inti__(self):\n",
        "    super(lr,self).__init__()\n",
        "    self.linear=nn.Linear(1,1)\n",
        "  def forward(self,x):\n",
        "    pred=self.linear(x)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "pajIAYzRmXKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Creation"
      ],
      "metadata": {
        "id": "mWQXmeDutsie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for doing with the data you need to import **torch.utils.data.Dataset**"
      ],
      "metadata": {
        "id": "RXRGlUdXt67c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "19Fb-n9uq1fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "MPO6vbOmug9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('spam.csv',encoding='ISO-8859-1')"
      ],
      "metadata": {
        "id": "t9O6cNH9vtwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Cifar(Dataset):\n",
        "  def __init__(self,file):\n",
        "    lines=open(file,'r').readlines()\n",
        "    lines=[line.strip() for line in lines]\n",
        "    self.data=pd.DataFrame(lines,columns=['label','text'])\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self,idx):\n",
        "    label=self.data.iloc[idx]['label']\n",
        "    text=self.data.iloc[idx]['text']\n",
        "    return label,text"
      ],
      "metadata": {
        "id": "DhkRxlVYuilj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader=DataLoader(data,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "qh1ZmQh2umET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataloader:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "4dfv8AhfwOkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TorchVision Datasets"
      ],
      "metadata": {
        "id": "A8hibRZlxyXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets.mnist as mnist"
      ],
      "metadata": {
        "id": "wOkqdXFMwXNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import transform from torchvision\n",
        "\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "eeLD3Bulye5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=mnist.MNIST(root='./data',train=True,download=True,transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "9gnHCyNdx_z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0][0]"
      ],
      "metadata": {
        "id": "pMFBC8YtyMRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'data' is your tensor and you want to display the first element of the first image\n",
        "# Check if data[0][0] has shape (1, 28, 28)\n",
        "image_tensor = data[0][0]  # This should be of shape (1, 28, 28)\n",
        "\n",
        "# Squeeze the tensor to remove the channel dimension\n",
        "image = image_tensor.squeeze(0)  # Now it should be of shape (28, 28)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image.numpy(), cmap='gray')  # Use cmap='gray' for grayscale images\n",
        "plt.axis('off')  # Optional: turn off axis labels\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "CSwYkO4by0N1",
        "outputId": "d854354a-7b2a-4692-b323-d30b97a71b85"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision as vision\n",
        "dataset=vision.datasets.MNIST(root='./data',train=True,download=True,transform=None)"
      ],
      "metadata": {
        "id": "M0cgFtO0zNIV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "048Kwm2g1DxO",
        "outputId": "4b0377ec-1167-4d1d-ec46-395734343855"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.Image.Image image mode=L size=28x28 at 0x7E43F96FA530>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cNVmdZbz_fW",
        "outputId": "753c2ab0-f6ef-405a-cc3b-a8fc3a11ef79"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<PIL.Image.Image image mode=L size=28x28 at 0x7E43F937CBE0>, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=dataset[0][0]"
      ],
      "metadata": {
        "id": "wdyQqnYV04rm"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.show()"
      ],
      "metadata": {
        "id": "bE-Xsu0Y06im"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: using this code print the image 'from PIL import Image\n",
        "# from IPython.display import display\n",
        "# # Assuming 'data' is your tensor and you want to display the first element of the first image\n",
        "# # Access the image from data\n",
        "# image_tensor = data[0][0]  # This should be a PIL Image object\n",
        "# # If image_tensor is a PIL Image, you can directly display it\n",
        "# display(image_tensor)'\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'data' is your tensor and you want to display the first element of the first image\n",
        "# Check if data[0][0] has shape (1, 28, 28)\n",
        "image_tensor = data[0][0]  # This should be of shape (1, 28, 28)\n",
        "\n",
        "# Squeeze the tensor to remove the channel dimension\n",
        "image = image_tensor.squeeze(0)  # Now it should be of shape (28, 28)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image.numpy(), cmap='gray')  # Use cmap='gray' for grayscale images\n",
        "plt.axis('off')  # Optional: turn off axis labels\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "wnsDq7EJ07mG",
        "outputId": "55561529-92ca-4a94-ac3f-e569b8e552a0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNvUKo1M1YUH",
        "outputId": "c0d7c96e-f260-4b26-8537-9da4c248759c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    ToTensor()\n",
              "    Normalize(mean=(0.5,), std=(0.5,))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transform"
      ],
      "metadata": {
        "id": "Q0PCb2Yd2K_3"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision"
      ],
      "metadata": {
        "id": "F5E_qUwT3oun"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IgByrSu3mgc",
        "outputId": "3173123a-b3b5-42ad-f28f-542e59c85e15"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    ToTensor()\n",
              "    Normalize(mean=(0.5,), std=(0.5,))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=torchvision.datasets.MNIST(root='./data/',train=True,download=True,transform=transforms)"
      ],
      "metadata": {
        "id": "O_-9mGW52a63"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader=DataLoader(data,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "BwqQXXQD2rpn"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in enumerate(dataloader):\n",
        "  print(j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "MXLlO59Y2w93",
        "outputId": "436687be-2af1-4025-f1d4-56075668ecc4"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'module' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-7b1281392a6c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AJxTZZbR3ASY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activation Functions"
      ],
      "metadata": {
        "id": "B32nohPe34GS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "x4sucNqf36dI"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b=torch.tensor([-2,-1,0,1,2])"
      ],
      "metadata": {
        "id": "rNwtAVq_4HHn"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.relu(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9A_iEsb4BwI",
        "outputId": "c163f017-f13d-42ee-cefb-8e1aba4bfefe"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.log_softmax(x,dim=1)"
      ],
      "metadata": {
        "id": "JhjWrSkS4Eko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: what are the different types of loss functions are available in torch library and initalize for each variable\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Initialize loss functions with example input tensors\n",
        "# You'll need to replace these with your actual data shapes\n",
        "\n",
        "# For regression tasks:\n",
        "# Mean Squared Error (MSE)\n",
        "mse_loss = nn.MSELoss()\n",
        "example_input_regression = torch.randn(10, 1)  # Example: 10 samples, 1 output\n",
        "example_target_regression = torch.randn(10, 1)\n",
        "mse_loss_value = mse_loss(example_input_regression, example_target_regression)\n",
        "print(f\"MSE Loss: {mse_loss_value}\")\n",
        "\n",
        "\n",
        "# Mean Absolute Error (MAE)\n",
        "mae_loss = nn.L1Loss()\n",
        "mae_loss_value = mae_loss(example_input_regression, example_target_regression)\n",
        "print(f\"MAE Loss: {mae_loss_value}\")\n",
        "\n",
        "# Smooth L1 Loss\n",
        "smooth_l1_loss = nn.SmoothL1Loss()\n",
        "smooth_l1_loss_value = smooth_l1_loss(example_input_regression, example_target_regression)\n",
        "print(f\"Smooth L1 Loss: {smooth_l1_loss_value}\")\n",
        "\n",
        "\n",
        "# For binary classification tasks:\n",
        "# Binary Cross Entropy (BCE)\n",
        "bce_loss = nn.BCELoss()\n",
        "example_input_binary = torch.sigmoid(torch.randn(10, 1))  # Example: 10 samples, 1 output (sigmoid output)\n",
        "example_target_binary = torch.randint(0, 2, (10, 1), dtype=torch.float32) # Example targets (0 or 1)\n",
        "bce_loss_value = bce_loss(example_input_binary, example_target_binary)\n",
        "print(f\"BCE Loss: {bce_loss_value}\")\n",
        "\n",
        "# For multi-class classification tasks:\n",
        "# Cross Entropy (CE)\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "example_input_multiclass = torch.randn(10, 5)  # Example: 10 samples, 5 classes (logits)\n",
        "example_target_multiclass = torch.randint(0, 5, (10,)) # Example targets (class indices)\n",
        "ce_loss_value = ce_loss(example_input_multiclass, example_target_multiclass)\n",
        "print(f\"Cross Entropy Loss: {ce_loss_value}\")\n",
        "\n",
        "\n",
        "# Negative Log Likelihood Loss (NLL) - Use with log_softmax\n",
        "nll_loss = nn.NLLLoss()\n",
        "example_input_nll = F.log_softmax(torch.randn(10,5), dim=1)\n",
        "example_target_nll = torch.randint(0, 5, (10,))\n",
        "nll_loss_value = nll_loss(example_input_nll, example_target_nll)\n",
        "print(f\"NLL Loss: {nll_loss_value}\")\n",
        "\n",
        "# KL Divergence\n",
        "kl_div_loss = nn.KLDivLoss()\n",
        "example_input_kl = F.log_softmax(torch.randn(10, 5), dim=1)\n",
        "example_target_kl = torch.randn(10, 5).exp()  # Needs to be probabilities\n",
        "kl_div_loss_value = kl_div_loss(example_input_kl, example_target_kl)\n",
        "print(f\"KL Divergence Loss: {kl_div_loss_value}\")"
      ],
      "metadata": {
        "id": "C51pbVR35IPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  test_loss=0\n",
        "  correct=0\n",
        "  model.eval()\n",
        "  test_dataloader=get_dataloader(train=False)\n",
        ""
      ],
      "metadata": {
        "id": "Jy37L5M65y3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'model.pth')"
      ],
      "metadata": {
        "id": "ALIvO-ex8ONV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v9Yzru6c8Yqd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}